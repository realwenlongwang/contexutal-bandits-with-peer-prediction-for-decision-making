{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Bandits Agent with Policy Gradient Method (Stochastic) in Prediction Markets Problem\n",
    "---\n",
    "This is a program that simulates an agent who trades in a prediction market. The problem that the prediction market aims to solve is to predict the real distribution of a random variable. We define the random variable as the colour of a bucket. The problem design comes from a human-subjective experiment for decision markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from main import stochastic_training_notebook\n",
    "from Environment import ScoreFunction, DecisionRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "learning_rate_theta = 1e-3\n",
    "learning_rate_wv = 1e-3\n",
    "memory_size = 16\n",
    "batch_size = 16\n",
    "training_episodes = int(1e6)\n",
    "decay_rate = 0\n",
    "beta1 = 0.9\n",
    "beta2 = 0.9999\n",
    "# Algorithm: adam, momentum, regular\n",
    "algorithm = 'regular'\n",
    "learning_std = False\n",
    "fixed_std = 0.3\n",
    "# Bucket parameters\n",
    "pr_red_ball_red_bucket = 2/3\n",
    "pr_red_ball_blue_bucket = 1/3\n",
    "# prior_red_list = [0.7, 0.3]\n",
    "prior_red_list = None\n",
    "sq_agent_num=1 # total agent number will be sq_agent_num + action_num * 3\n",
    "action_num=2\n",
    "score_func = ScoreFunction.LOG\n",
    "agent_list = []\n",
    "evaluation_step = 1\n",
    "\n",
    "agent_list, pd_outcome_list, prior_outcome_list, nb_outcome_list, loss_list = stochastic_training_notebook(agent_list, learning_rate_theta, learning_rate_wv,\n",
    "                             memory_size, batch_size, training_episodes,\n",
    "                             decay_rate, beta1, beta2, algorithm, learning_std,\n",
    "                             fixed_std, pr_red_ball_red_bucket, pr_red_ball_blue_bucket,\n",
    "                             prior_red_list, sq_agent_num, action_num, score_func, evaluation_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(prior_outcome_list))\n",
    "print(np.mean(pd_outcome_list))\n",
    "print(np.mean(nb_outcome_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(loss_list))\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for action_agent_list in agent_list:\n",
    "    for agent in action_agent_list:\n",
    "        agent.reward_history_plot()\n",
    "    #     agent.report_history_plot()\n",
    "        agent.mean_gradients_history_plot()\n",
    "        agent.mean_gradients_successive_dot_product_plot()\n",
    "    #     agent.mean_history_plot()\n",
    "        agent.mean_weights_history_plot()\n",
    "        agent.std_gradients_history_plot()\n",
    "        agent.std_history_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_history_df = agent_list[0][0].reward_history_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_history_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reward_history_df = self.reward_history_dataframe()\n",
    "for bucket_no in range(1):\n",
    "    fig, axs = plt.subplots(2, figsize=(15, 4 * 2))\n",
    "    reward_column_name = 'bucket_' + str(bucket_no) + '_reward'\n",
    "    v_column_name = 'bucket_' + str(bucket_no) + '_v'\n",
    "    running_average_reward = reward_history_df[reward_column_name].expanding().mean()\n",
    "    axs[0].hlines(y=0.0, xmin=0, xmax=reward_history_df.shape[0], colors='black', linestyles='dashdot')\n",
    "    axs[0].plot(reward_history_df[v_column_name], label=v_column_name, zorder=-100)\n",
    "    axs[0].plot(running_average_reward, zorder=-99,\n",
    "                label='Average ' + reward_column_name)\n",
    "\n",
    "    last_quarter_num = 3 * len(reward_history_df) // 4\n",
    "    ymin = running_average_reward.iloc[-1] - 0.005\n",
    "    ymax = running_average_reward.iloc[-1] + 0.01\n",
    "    axs[1].plot(reward_history_df[v_column_name], zorder=-100)\n",
    "    axs[1].plot(running_average_reward, zorder=-99)\n",
    "    axs[1].set_xlim(left=last_quarter_num)\n",
    "    axs[1].set_ylim(top=ymax, bottom=ymin)\n",
    "    fig.legend(loc='upper right')\n",
    "    fig.suptitle(' Reward History')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = reward_history_df[reward_column_name].expanding().mean()\n",
    "a.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_history_df_df_history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_history_df = agent_list[0].report_history_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_history_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_history_df = agent_list[2].report_history_dataframe()\n",
    "report_history_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy import stats\n",
    "from scipy.special import logit, expit\n",
    "from Environment import expected_log_reward_red_ball, analytical_best_report_ru_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mu = 0\n",
    "sigma = 0.2\n",
    "prior_red = 0.5\n",
    "colours = ['red', 'blue', 'yellow', 'green', 'purple']\n",
    "variance = np.square(sigma)\n",
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "z = np.linspace(mu-2*sigma, mu+2*sigma, 5)\n",
    "fig, axs = plt.subplots(5, figsize=(14, 4*5))\n",
    "axs[0].plot(x, stats.norm.pdf(x, mu, sigma))\n",
    "axs[0].vlines(z, ymin=0, ymax=np.max(stats.norm.pdf(x=x, loc=mu, scale=sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(z, zip(z, [0]*5)):\n",
    "    axs[0].annotate('%.3f'%value, xy=coord)\n",
    "axs[1].plot(expit(x), stats.norm.pdf(x, mu, sigma))\n",
    "axs[1].vlines(expit(z), ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(expit(z), zip(expit(z), [0]*5)):\n",
    "    axs[1].annotate('%.3f'%value, xy=coord)\n",
    "axs[2].plot(np.log(expit(x))-np.log(1/2), stats.norm.pdf(x, mu, sigma))\n",
    "# axs[2].plot(np.log(1/2) - np.log(expit(x)), stats.norm.pdf(x, mu, sigma))\n",
    "axs[2].vlines(np.log(expit(z))-np.log(1/2), ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(np.log(expit(z))-np.log(1/2), zip(np.log(expit(z))-np.log(1/2), [0]*5)):\n",
    "    axs[2].annotate('%.3f'%value, xy=coord)\n",
    "axs[3].plot(expit(x) - (np.square(expit(x)) + np.square(1 - expit(x)))/2 - 0.25, stats.norm.pdf(x, mu, sigma))\n",
    "axs[3].vlines(expit(z) - (np.square(expit(z)) + np.square(1 - expit(z)))/2 - 0.25, ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(expit(z) - (np.square(expit(z)) + np.square(1 - expit(z)))/2 - 0.25, zip(expit(z) - (np.square(expit(z)) + np.square(1 - expit(z)))/2 - 0.25, [0]*5)):\n",
    "    axs[3].annotate('%.3f'%value, xy=coord)\n",
    "actual_pr_ru_rs = analytical_best_report_ru_rs(prior_red, pr_red_ball_red_bucket, pr_red_ball_blue_bucket)\n",
    "expected_init = expected_log_reward_red_ball(actual_pr_ru_rs, 1/2, prior_red)\n",
    "expected_z = expected_log_reward_red_ball(actual_pr_ru_rs, np.array(expit(z)), prior_red)\n",
    "expected_x = expected_log_reward_red_ball(actual_pr_ru_rs, np.array(expit(x)), prior_red)\n",
    "# axs[4].plot(expected_x-expected_init, stats.norm.pdf(x, mu, sigma))\n",
    "# axs[4].vlines(expected_z-expected_init, ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "# for value, coord in zip(expected_z-expected_init, zip(expected_z-expected_init, [0]*5)):\n",
    "#     axs[4].annotate('%.3f'%value, xy=coord)\n",
    "axs[4].plot(x, expected_x-expected_init)\n",
    "axs[4].vlines(z, ymin=np.min(expected_x-expected_init), ymax=np.max(expected_x-expected_init), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(z, zip(z, [np.min(expected_x-expected_init)]*5)):\n",
    "    axs[4].annotate('%.3f'%value, xy=coord)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Environment import expected_log_reward_red_ball, expected_log_reward_blue_ball, analytical_best_report_ru_rs, analytical_best_report_ru_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ru1 = 1/4\n",
    "pr_ru2 = 3/4\n",
    "pr_bs_ru = 1/3\n",
    "pr_bs_bu = 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "r2 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "r1v, r2v = np.meshgrid(r1, r2)\n",
    "actual_pr_ru_bs1 = analytical_best_report_ru_bs(pr_ru=pr_ru1, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "actual_pr_ru_bs2 = analytical_best_report_ru_bs(pr_ru=pr_ru2, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "rv = r1v * (r1v > r2v) + r2v * (r1v <= r2v)\n",
    "actual_pr_ru_bsv = actual_pr_ru_bs1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "pr_ruv = pr_ru1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pr_ru_bsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm_expected_log_reward_blue_ball(pr_ru1, pr_ru2, pr_bs_ru, pr_bs_bu):\n",
    "    r1 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r2 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r1v, r2v = np.meshgrid(r1, r2)\n",
    "    actual_pr_ru_bs1 = analytical_best_report_ru_bs(pr_ru=pr_ru1, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "    actual_pr_ru_bs2 = analytical_best_report_ru_bs(pr_ru=pr_ru2, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "    rv = r1v * (r1v > r2v) + r2v * (r1v <= r2v)\n",
    "    actual_pr_ru_bsv = actual_pr_ru_bs1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    pr_ruv = pr_ru1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    return r1v, r2v, expected_log_reward_blue_ball(actual_pr_ru_bs=actual_pr_ru_bsv, estimated_pr_ru_bs=rv, pr_ru=pr_ruv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1v, r2v, z = dm_expected_log_reward_blue_ball( pr_ru1, pr_ru2, pr_bs_ru, pr_bs_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "# ax.contour3D(r1v, r2v, z, 100, cmap='binary')\n",
    "ax.plot_surface(r1v, r2v, z, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('r1')\n",
    "ax.set_ylabel('r2')\n",
    "ax.set_zlabel('expectation')\n",
    "ax.view_init(90, 60)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ru1 = 1/4\n",
    "pr_ru2 = 3/4\n",
    "pr_rs_ru = 2/3\n",
    "pr_rs_bu = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm_expected_log_reward_red_ball(pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu):\n",
    "    r1 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r2 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r1v, r2v = np.meshgrid(r1, r2)    \n",
    "    actual_pr_ru_rs1 = analytical_best_report_ru_rs(pr_ru=pr_ru1, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)\n",
    "    actual_pr_ru_rs2 = analytical_best_report_ru_rs(pr_ru=pr_ru2, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)   \n",
    "    rv = r1v * (r1v > r2v) + r2v * (r1v <= r2v)\n",
    "    actual_pr_ru_rsv = actual_pr_ru_rs1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    pr_ruv = pr_ru1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    return r1v, r2v, expected_log_reward_red_ball(actual_pr_ru_rs=actual_pr_ru_rsv, estimated_pr_ru_rs=rv, pr_ru=pr_ruv)\n",
    "\n",
    "r1v, r2v, z = dm_expected_log_reward_red_ball(pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "# ax.contour3D(r1v, r2v, z, 100, cmap='binary')\n",
    "ax.plot_surface(r1v, r2v, z, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('r1')\n",
    "ax.set_ylabel('r2')\n",
    "ax.set_zlabel('expectation')\n",
    "ax.view_init(90, 60)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Surface(z=z, x=r1v, y=r2v)])\n",
    "fig.update_layout(title='Mt Bruno Elevation', autosize=True,\n",
    "#                   width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ru1 = 1/4\n",
    "pr_ru2 = 3/4\n",
    "pr_rs_ru = 2/3\n",
    "pr_rs_bu = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import Generator, PCG64\n",
    "def stochastic_decision_rule(r1v, r2v, probabilities, pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu):\n",
    "#     generator = Generator(PCG64())\n",
    "    result_array = np.zeros(r1v.shape)\n",
    "    r_stack_v = np.dstack((r1v, r2v))\n",
    "    for i in range(r_stack_v.shape[0]):\n",
    "        for j in range(r_stack_v.shape[1]):\n",
    "            r1, r2 = r_stack_v[i][j]\n",
    "            if r1 > r2:\n",
    "                pr = probabilities\n",
    "            else:\n",
    "                pr = probabilities[::-1]\n",
    "            actual_pr_ru_rs1 = analytical_best_report_ru_rs(pr_ru=pr_ru1, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)\n",
    "            actual_pr_ru_rs2 = analytical_best_report_ru_rs(pr_ru=pr_ru2, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu) \n",
    "            result_array[i][j] = expected_log_reward_red_ball(actual_pr_ru_rs=actual_pr_ru_rs1, estimated_pr_ru_rs=r1, pr_ru=pr_ru1)/pr[0] + expected_log_reward_red_ball(actual_pr_ru_rs=pr_ru2, estimated_pr_ru_rs=r2, pr_ru=pr_ru2)/pr[1]\n",
    "            \n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z = stochastic_decision_rule(r1v, r2v, [0.8, 0.2], pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pr_ru_rs1 = analytical_best_report_ru_rs(pr_ru=pr_ru1, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)\n",
    "actual_pr_ru_rs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Surface(z=z, x=r1v, y=r2v)])\n",
    "fig.update_layout(title='Mt Bruno Elevation', autosize=True,\n",
    "#                   width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (contexutal-bandits-problem-continous-actionspace-prediction-market)",
   "language": "python",
   "name": "pycharm-edabad71"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
